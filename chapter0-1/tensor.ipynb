{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.3.1+cu118'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar = torch.tensor(5)\n",
    "\n",
    "scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor([1,2,3], dtype=torch.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3], dtype=torch.int8)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "a[0] = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overflow\n"
     ]
    }
   ],
   "source": [
    "# test overflow\n",
    "try:\n",
    "  a[0] = 300\n",
    "except RuntimeError:\n",
    "  print('overflow')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(38, dtype=torch.int8)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a @ a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.4234, -0.1143],\n",
       "        [ 0.5270, -0.6216]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.randn(2, 3)\n",
    "b = torch.randn(2, 3)\n",
    "\n",
    "a @ b.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.7803,  0.6673, -0.1511],\n",
       "        [-1.0524, -1.1039,  0.1051],\n",
       "        [-2.9647, -1.3949,  1.1254]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.T @ b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.4044, -0.1256,  1.1446],\n",
       "        [ 0.3760, -0.9783, -0.0193]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a * b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.8888],\n",
       "        [2.9941],\n",
       "        [3.8659],\n",
       "        [2.3848],\n",
       "        [3.0561],\n",
       "        [4.0631],\n",
       "        [3.0783],\n",
       "        [3.3534],\n",
       "        [2.3534],\n",
       "        [2.8407]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand(10, 10)\n",
    "b = torch.rand(10, 1)\n",
    "a = torch.rand(10, 1)\n",
    "\n",
    "y =  x @ a + b\n",
    "\n",
    "y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand(1, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0486, -0.1841]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layers = [\n",
    "  torch.nn.Linear(10, 10),\n",
    "  torch.nn.Linear(10, 5),\n",
    "  torch.nn.Linear(5, 2)\n",
    "]\n",
    "\n",
    "model = torch.nn.Sequential(*layers)\n",
    "\n",
    "model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 10]) torch.Size([1, 10])\n",
      "torch.Size([1, 10])\n",
      "torch.Size([5, 10]) torch.Size([1, 10])\n",
      "torch.Size([1, 5])\n",
      "torch.Size([2, 5]) torch.Size([1, 5])\n",
      "torch.Size([1, 2])\n"
     ]
    }
   ],
   "source": [
    "def my_linear(w: torch.Tensor,b: torch.Tensor, x: torch.Tensor) -> torch.tensor:\n",
    "  print(w.shape, x.shape)\n",
    "  return x @ w.T + b\n",
    "\n",
    "my_lin = [partial(my_linear,layer.weight, layer.bias) for layer in layers]\n",
    "\n",
    "for f in my_lin:\n",
    "  x = f(x)\n",
    "  print(x.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0486, -0.1841]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Activation test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5507, 0.6566, 0.7220, 0.6353, 0.6548, 0.5035, 0.6156, 0.7106, 0.5959,\n",
       "         0.6697]])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand(1, 10)\n",
    "\n",
    "sigmoid = torch.nn.Sigmoid()\n",
    "\n",
    "sigmoid(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.5507, 0.6566, 0.7220, 0.6353, 0.6548, 0.5035, 0.6156, 0.7106, 0.5959,\n",
       "        0.6697])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def my_sigmoid(x: torch.Tensor) -> torch.Tensor:\n",
    "  return torch.tensor([torch.exp(val)/ (1+torch.exp(val)) if val > torch.tensor(0) else 1/(1+torch.exp(-x)) for val in x.squeeze()])\n",
    "my_sigmoid(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0683, 0.1065, 0.1447, 0.0971, 0.1057, 0.0565, 0.0892, 0.1368, 0.0822,\n",
       "         0.1130]])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax = torch.nn.Softmax(dim=1)\n",
    "\n",
    "softmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0683, 0.1065, 0.1447, 0.0971, 0.1057, 0.0565, 0.0892, 0.1368, 0.0822,\n",
       "        0.1130])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def my_softmax(x: torch.Tensor) -> torch.Tensor:\n",
    "  return torch.tensor([torch.exp(val)/torch.sum(torch.exp(x)) for val in x.squeeze(0)])\n",
    "\n",
    "my_softmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegression(torch.nn.Module):\n",
    "  def __init__(self):\n",
    "    super(LinearRegression, self).__init__()\n",
    "    \n",
    "    self.weight = torch.nn.Parameter(torch.randn(1, requires_grad=True, dtype=torch.float))\n",
    "    self.bias = torch.nn.Parameter(torch.randn(1, requires_grad=True, dtype=torch.float)) \n",
    "    \n",
    "  def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "    return self.weight * x + self.bias\n",
    "  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression().eval()\n",
    "\n",
    "input = (torch.rand(1),)\n",
    "\n",
    "ex = torch.export.export(model, input)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.export.save(ex, 'model.pt2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (804892183.py, line 42)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[2], line 42\u001b[1;36m\u001b[0m\n\u001b[1;33m    self.expansive_1 =\u001b[0m\n\u001b[1;37m                      ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "class Unet(nn.Module):\n",
    "  def __init__(self):\n",
    "    self.contracting_1 = nn.Sequential([\n",
    "      nn.Conv2d(in_channels=3, out_channels=64),\n",
    "      nn.BatchNorm2d(),\n",
    "      nn.ReLU(),\n",
    "      nn.Conv2d(in_channels=3, out_channels=64),\n",
    "      nn.BatchNorm2d(),\n",
    "      nn.ReLU(),\n",
    "    ])\n",
    "    self.contracting_2 = nn.Sequential([\n",
    "      nn.MaxPool2d((2, 2), stride=2),\n",
    "      nn.Conv2d(in_channels=64, out_channels=128),\n",
    "      nn.BatchNorm2d(),\n",
    "      nn.ReLU(),\n",
    "      nn.Conv2d(in_channels=64, out_channels=128),\n",
    "      nn.BatchNorm2d(),\n",
    "      nn.ReLU(),\n",
    "    ])\n",
    "    self.contracting_3 = nn.Sequential([\n",
    "      nn.MaxPool2d((2, 2), stride=2),\n",
    "      nn.Conv2d(in_channels=128, out_channels=256),\n",
    "      nn.BatchNorm2d(),\n",
    "      nn.ReLU(),\n",
    "      nn.Conv2d(in_channels=128, out_channels=256),\n",
    "      nn.BatchNorm2d(),\n",
    "      nn.ReLU(),\n",
    "    ])\n",
    "    self.contracting_4 = nn.Sequential([\n",
    "      nn.MaxPool2d((2, 2), stride=2),\n",
    "      nn.Conv2d(in_channels=256, out_channels=512),\n",
    "      nn.BatchNorm2d(),\n",
    "      nn.ReLU(),\n",
    "      nn.Conv2d(in_channels=256, out_channels=512),\n",
    "      nn.BatchNorm2d(),\n",
    "      nn.ReLU(),\n",
    "    ])\n",
    "    self.contracting_5 = nn.Sequential([\n",
    "      nn.MaxPool2d((2, 2), stride=2),\n",
    "      nn.Conv2d(in_channels=512, out_channels=1024),\n",
    "      nn.BatchNorm2d(),\n",
    "      nn.ReLU(),\n",
    "      nn.Conv2d(in_channels=512, out_channels=1024),\n",
    "      nn.BatchNorm2d(),\n",
    "      nn.ReLU(),\n",
    "    ])\n",
    "    \n",
    "    self.expansive_1 = nn.Sequential([\n",
    "      nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True),\n",
    "      nn.Conv2d(in_channels=1024, out_channels=512),\n",
    "      nn.BatchNorm2d(),\n",
    "      nn.ReLU(),\n",
    "      nn.Conv2d(in_channels=1024, out_channels=512),\n",
    "      nn.BatchNorm2d(),\n",
    "      nn.ReLU(),\n",
    "    ])\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
